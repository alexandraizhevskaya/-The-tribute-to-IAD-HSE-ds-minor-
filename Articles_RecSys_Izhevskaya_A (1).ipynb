{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Articles_RecSys_Izhevskaya_A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44c14fc3d6604c1e9e5a003ae6afb624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_866726694d1d424f92e2247ef49c764b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73962cca4483461d8d181f816f682145",
              "IPY_MODEL_f15f04cff75244719056ee88001171e3"
            ]
          }
        },
        "866726694d1d424f92e2247ef49c764b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73962cca4483461d8d181f816f682145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2fca097616f4f8a916cfcb9b114eb3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4aceeea083d47f5ab7a2ab0df4b99dd"
          }
        },
        "f15f04cff75244719056ee88001171e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e253d3bcfe94467fb57a0436e615052c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "328050it [00:14, 22321.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_716a886d329740ee837e1b33aba9773c"
          }
        },
        "d2fca097616f4f8a916cfcb9b114eb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4aceeea083d47f5ab7a2ab0df4b99dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e253d3bcfe94467fb57a0436e615052c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "716a886d329740ee837e1b33aba9773c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kie8w17nEfPK",
        "colab_type": "text"
      },
      "source": [
        "# Articles RecSys\n",
        "\n",
        "---\n",
        "\n",
        "В данном ноутбуке содержится мое решение для соревнования по ИАД Articles RecSys. После рассмотрения всех возможных вариантов (после долгого, очень долгого пути проб и ошибок...)  я решила использовать Гибридный подход в данной задаче и применить факторизационную машину (библиотека Lightfm), которая эффективно использует данные о взаимодействиях пользователей с айтемами, а также учитывает метаинформацию о пользователях/айтемах (в нашем случае об айтемах). Таким образом, удается эффективнее справляться с проблемой холодного старта."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpbf1wiiMEFG",
        "colab_type": "code",
        "outputId": "59b1c9d7-a955-4d3a-a5e9-bd7a1c7dac3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "! pip3 install lightfm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.6/dist-packages (1.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaDc1X-Tlc3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# импортируем необходимые библиотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "\n",
        "#import tqdm\n",
        "from scipy.sparse import csr_matrix,  coo_matrix, vstack, hstack\n",
        "from scipy.sparse import eye as eye\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as tfdf\n",
        "from lightfm import LightFM\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import string\n",
        "import re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjF4_GqdlyH8",
        "colab_type": "code",
        "outputId": "233cf48d-4bf6-4c30-b9d0-37e6540ef85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# код для загрузки датасета с помощью kaggle api (нужен файл kaggle.json)\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 /root/.kaggle/kaggle.json\n",
        "import kaggle\n",
        "!kaggle competitions download -c recsys-iad-challenge\n",
        "\n",
        "! unzip \"/content/items.json.zip\"\n",
        "! unzip \"/content/train.json.zip\"\n",
        "! unzip \"/content/random_benchmark.csv.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading random_benchmark.csv.zip to /content\n",
            " 46% 5.00M/10.9M [00:00<00:00, 15.4MB/s]\n",
            "100% 10.9M/10.9M [00:00<00:00, 27.6MB/s]\n",
            "Downloading train.json.zip to /content\n",
            " 95% 223M/235M [00:03<00:00, 95.6MB/s]\n",
            "100% 235M/235M [00:03<00:00, 69.0MB/s]\n",
            "Downloading items.json.zip to /content\n",
            " 94% 348M/368M [00:05<00:00, 48.2MB/s]\n",
            "100% 368M/368M [00:05<00:00, 66.3MB/s]\n",
            "Archive:  /content/items.json.zip\n",
            "  inflating: items.json              \n",
            "Archive:  /content/train.json.zip\n",
            "  inflating: train.json              \n",
            "Archive:  /content/random_benchmark.csv.zip\n",
            "  inflating: random_benchmark.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KemnB-sx32wm",
        "colab_type": "code",
        "outputId": "05789478-1d25-4583-b212-0746d7c42abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "44c14fc3d6604c1e9e5a003ae6afb624",
            "866726694d1d424f92e2247ef49c764b",
            "73962cca4483461d8d181f816f682145",
            "f15f04cff75244719056ee88001171e3",
            "d2fca097616f4f8a916cfcb9b114eb3f",
            "d4aceeea083d47f5ab7a2ab0df4b99dd",
            "e253d3bcfe94467fb57a0436e615052c",
            "716a886d329740ee837e1b33aba9773c"
          ]
        }
      },
      "source": [
        "# данный код для загрузки описания айтемов был любезно предоставлен нашим преподавателем\n",
        "\n",
        "%%time\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "items_list=[]\n",
        "with tqdm(open('./items.json')) as inf:\n",
        "  for line in inf:\n",
        "    item=json.loads(line)\n",
        "    items_list.append(item)\n",
        "\n",
        "items_df=pd.DataFrame(items_list).set_index('itemId')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44c14fc3d6604c1e9e5a003ae6afb624",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 14.2 s, sys: 1.99 s, total: 16.1 s\n",
            "Wall time: 15.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4oQC00FJwUX",
        "colab_type": "text"
      },
      "source": [
        "## Пару слов о фичах\n",
        "\n",
        "---\n",
        "\n",
        "Я решила использовать  tf-idf как самый доступный и при этом достаточно эффективный метод для получения векторных представлений. Были использованы  title и content, предварительно обработанные с целью удаления знаков препинания. Полученные матрицы, несущие в себе информацию о контенте статьи, были сконкатенированы и скормлены фактаризационной машине в качестве item_features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d65R9UH0lyYN",
        "colab_type": "code",
        "outputId": "ac0b3c96-a195-40a4-9020-c9c64fc30357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# функция для простенькой предобработки текста\n",
        "def delete_punctuation(x):\n",
        "\n",
        "\n",
        "    punctuation = list(string.punctuation)\n",
        "    return ''.join([a if a not in punctuation + ['«»\\n--'] else ' ' for a in x])\n",
        "\n",
        "\n",
        "items_df.title = items_df.title.apply(delete_punctuation)\n",
        "items_df.content = items_df.content.apply(delete_punctuation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4b39be0a02e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete_punctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mitems_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete_punctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4043\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4b39be0a02e5>\u001b[0m in \u001b[0;36mdelete_punctuation\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpunctuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunctuation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'«»\\n--'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4b39be0a02e5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpunctuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunctuation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'«»\\n--'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-TmEnVXNILR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создание фичей\n",
        "vectorizer_t = tfdf(lowercase=False, min_df=90, max_df=0.01)\n",
        "tf_idf_titles = vectorizer_t.fit_transform(items_df.title.values)\n",
        "vectorizer_c = tfdf(lowercase=False, min_df=90, max_df=0.01)\n",
        "tf_idf_content = vectorizer_c.fit_transform(items_df.content.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l18UHek1Ore0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# identity матрица \n",
        "num_items= len(items_df)\n",
        "a = eye(num_items)\n",
        "# полученные фичи, которые мы подадим в факторизационную машину\n",
        "items_features =hstack([a, tf_idf_titles, tf_idf_content], format=\"csr\")\n",
        "items_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B0M5m6RSZEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# код для загрузки основного датасета и создания из него спарс матрицы \n",
        "users = []\n",
        "items = []\n",
        "data = []\n",
        "\n",
        "with open(\"/content/train.json\", 'r') as f:\n",
        "  for line in f:\n",
        "    user = json.loads(line)\n",
        "    for item, rating in user['trainRatings'].items():\n",
        "      users.append(user['userId'])\n",
        "      items.append(item)\n",
        "      if rating == 0:\n",
        "        data.append(-1)\n",
        "      else:\n",
        "        data.append(rating)\n",
        "  \n",
        "# основные данные в формате coo_matrix: клики обозначены 1 (позитивное взаимодействие)\n",
        "# и отсутствие кликов -1 (негативное взаимодействие)\n",
        "interaction_matrix = coo_matrix((data, (users, list(map(int, items)))))\n",
        "interaction_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpfvjA5gMULM",
        "colab_type": "text"
      },
      "source": [
        "# Обучение модели\n",
        "\n",
        "---\n",
        "\n",
        "Итак, в итоге лучший результат был получен с помощью модели с векторами размерностью 150 (были попробованы и другие: но меньше - ухудшается качество, больше - слишком долгое время обучения). В качестве оптимизируемой функции был выбран logloss, так как присутствуют как позитивные, так и негативные взаимодействия. Модель обучалась  5 эпох."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWluszfnenP9",
        "colab_type": "code",
        "outputId": "08f24c7c-a6ba-4d8a-d671-9d8d67dafc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "n_Components = 150\n",
        "n_Epochs = 5\n",
        "seed= 10\n",
        "\n",
        "model= LightFM(loss=\"logistic\", no_components=n_Components, random_state=seed)\n",
        "                          \n",
        "model.fit_partial(interaction_matrix, item_features=items_features, epochs=n_Epochs, num_threads=cpu_count(), verbose=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fb9a41fd8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rih1_tGFOKIJ",
        "colab_type": "text"
      },
      "source": [
        "## Создание итогового сабмита для кэггл\n",
        "\n",
        "---\n",
        "\n",
        "В этой части все просто - с помощью полученной модели и фичей создаем предсказание для пользователей из файла random_benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWanIo8HOec3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = pd.read_csv(\"/content/random_benchmark.csv\")\n",
        "prediction[\"preds\"] = model.predict(prediction.userId.values,\n",
        "                                    prediction.itemId.values,\n",
        "                                    item_features = items_features,\n",
        "                                    num_threads=cpu.count())\n",
        "\n",
        "\n",
        "\n",
        "prediction.sort_values(['userId', 'preds'], ascending=[True, False], inplace=True)\n",
        "prediction.drop('preds', inplace=True)\n",
        "prediction.to_csv(\"with_identity1.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}